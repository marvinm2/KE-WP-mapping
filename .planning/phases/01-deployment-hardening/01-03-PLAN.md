---
phase: 01-deployment-hardening
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/embedding_utils.py
  - scripts/precompute_ke_embeddings.py
  - scripts/precompute_pathway_title_embeddings.py
  - scripts/precompute_go_embeddings.py
  - scripts/precompute_pathway_embeddings.py
  - src/services/embedding.py
  - src/suggestions/go.py
  - scoring_config.yaml
autonomous: true
requirements:
  - DEPLOY-02
  - DEPLOY-04

must_haves:
  truths:
    - "Embedding files are saved as .npz (not .npy) and load without allow_pickle=True"
    - "Embedding vectors are normalized to unit length at save time — dot product equals cosine similarity at query time"
    - "All five cosine similarity computations in embedding.py are replaced by plain np.dot() calls"
    - "The two allow_pickle=True loads in go.py are replaced by NPZ loaders"
    - "scoring_config.yaml embedding paths end in .npz"
  artifacts:
    - path: "scripts/embedding_utils.py"
      provides: "save_embeddings() uses np.savez with normalized matrix and dtype=str ids"
      contains: "np.savez"
    - path: "src/services/embedding.py"
      provides: "Three _load_precomputed_* methods use np.load NPZ without allow_pickle"
      contains: "allow_pickle"
    - path: "src/suggestions/go.py"
      provides: "Two _load_go_* methods use np.load NPZ without allow_pickle"
      contains: "allow_pickle"
    - path: "scoring_config.yaml"
      provides: "Embedding paths updated to .npz extension"
      contains: ".npz"
  key_links:
    - from: "scripts/embedding_utils.py"
      to: "src/services/embedding.py"
      via: "NPZ file written by save_embeddings, read by _load_precomputed_embeddings"
      pattern: "np\\.savez.*ids.*matrix"
    - from: "scripts/embedding_utils.py"
      to: "src/suggestions/go.py"
      via: "NPZ file written by precompute_go_embeddings, read by _load_go_embeddings"
      pattern: "np\\.savez.*ids.*matrix"
---

<objective>
Migrate all embedding files from pickle-based .npy dict format to NPZ matrix format, and replace cosine similarity computations with dot product (valid after pre-normalization at save time).

Purpose: The current approach uses `np.load(path, allow_pickle=True).item()` which deserializes arbitrary Python objects — a security risk and the source of fragile loading. Switching to `np.savez` with typed arrays eliminates pickle entirely. Pre-normalizing vectors at save time means dot product is mathematically equivalent to cosine similarity but faster (no per-query norm computation — closes GitHub issue #65).

Output: Updated embedding_utils.py, all 4 precompute scripts, embedding.py (3 loaders + 5 cosine → dot replacements), go.py (2 loaders), scoring_config.yaml (path extensions).
</objective>

<execution_context>
@/home/marvin/.claude/get-shit-done/workflows/execute-plan.md
@/home/marvin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-deployment-hardening/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update save_embeddings() to NPZ with pre-normalized matrix and update scoring_config.yaml paths</name>
  <files>scripts/embedding_utils.py, scoring_config.yaml</files>
  <action>
    **scripts/embedding_utils.py** — Replace the `save_embeddings()` function (lines 68–84 currently):

    ```python
    def save_embeddings(embeddings, path):
        """
        Save embeddings dict to .npy file with size reporting.
        ...
        """
        logger.info(f"Saving {len(embeddings)} embeddings to {path}...")
        np.save(path, embeddings)

        file_size_mb = os.path.getsize(path) / 1024 / 1024
        logger.info(f"Saved: {file_size_mb:.2f} MB")

        if embeddings:
            sample_id = next(iter(embeddings))
            logger.info(f"Sample: {sample_id}, shape: {embeddings[sample_id].shape}")
    ```

    with:

    ```python
    def save_embeddings(embeddings: dict, path: str):
        """
        Save embeddings dict as NPZ matrix format with pre-normalized vectors (no pickle).

        Format: two arrays in the .npz file:
          - 'ids': 1D Unicode string array of embedding keys (dtype=str, NOT dtype=object)
          - 'matrix': 2D float32 array of shape (N, embedding_dim), each row unit-normalized

        Pre-normalization means dot product == cosine similarity at query time (no per-query
        norm computation needed). Using dtype=str for ids avoids pickle requirement on load.

        Args:
            embeddings: Dict mapping ID string -> numpy embedding vector
            path: Output path (accepts .npy or no extension; always writes .npz)
        """
        if not embeddings:
            logger.warning("save_embeddings called with empty dict, skipping save")
            return

        # Always write to .npz extension regardless of input path
        npz_path = path.replace('.npy', '').rstrip('.')

        # Build ids array with Unicode dtype (NOT dtype=object — that requires pickle on load)
        ids = np.array(list(embeddings.keys()), dtype=str)

        # Build and normalize matrix
        matrix = np.array(list(embeddings.values()), dtype=np.float32)
        norms = np.linalg.norm(matrix, axis=1, keepdims=True)
        # Guard against zero vectors (avoid division by zero)
        norms = np.where(norms == 0.0, 1.0, norms)
        matrix = (matrix / norms).astype(np.float32)

        logger.info("Saving %d normalized embeddings to %s.npz ...", len(embeddings), npz_path)
        np.savez(npz_path, ids=ids, matrix=matrix)

        actual_path = npz_path + '.npz'
        file_size_mb = os.path.getsize(actual_path) / 1024 / 1024
        logger.info("Saved: %.2f MB (shape: %s)", file_size_mb, str(matrix.shape))

        sample_id = next(iter(embeddings))
        logger.info("Sample id: %s, vector norm after normalization: %.6f",
                    sample_id, float(np.linalg.norm(matrix[0])))
    ```

    **scoring_config.yaml** — Update the two embedding path references (lines 172–173) from `.npy` to `.npz`:

    Find and replace:
    - `precomputed_embeddings: "data/pathway_embeddings.npy"` → `precomputed_embeddings: "data/pathway_embeddings.npz"`
    - `precomputed_ke_embeddings: "data/ke_embeddings.npy"` → `precomputed_ke_embeddings: "data/ke_embeddings.npz"`

    These paths are read by `src/services/container.py` when initializing the embedding service.
  </action>
  <verify>
    Test save_embeddings writes correct NPZ:
    ```bash
    cd /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping
    python -c "
    import numpy as np, tempfile, os, sys
    sys.path.insert(0, '.')
    from scripts.embedding_utils import save_embeddings

    # Create test embeddings
    test_embs = {
        'KE1': np.array([1.0, 0.0, 0.0]),
        'KE2': np.array([0.0, 1.0, 0.0]),
        'KE3': np.array([3.0, 4.0, 0.0]),  # norm=5, should normalize to [0.6, 0.8, 0.0]
    }

    with tempfile.TemporaryDirectory() as d:
        out = os.path.join(d, 'test_embs.npy')  # .npy input, .npz output
        save_embeddings(test_embs, out)
        npz = np.load(os.path.join(d, 'test_embs.npz'))
        ids = npz['ids']
        matrix = npz['matrix']
        print('ids dtype:', ids.dtype, '(must be U-type, not object)')
        assert ids.dtype.kind == 'U', f'ids dtype is object — pickle required! Got: {ids.dtype}'
        print('matrix shape:', matrix.shape)
        norms = np.linalg.norm(matrix, axis=1)
        print('norms (all should be ~1.0):', norms)
        assert all(abs(n - 1.0) < 1e-5 for n in norms), 'Not normalized!'
        print('ALL CHECKS PASSED')
    "
    ```

    Check scoring_config.yaml paths:
    ```bash
    grep "precomputed_embeddings\|precomputed_ke_embeddings" /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/scoring_config.yaml
    ```
    Both must show `.npz`.
  </verify>
  <done>save_embeddings() writes .npz files with Unicode dtype ids (no pickle) and unit-normalized float32 matrix; scoring_config.yaml uses .npz paths.</done>
</task>

<task type="auto">
  <name>Task 2: Update all embedding loaders to NPZ format and replace cosine with dot product</name>
  <files>src/services/embedding.py, src/suggestions/go.py, scripts/precompute_ke_embeddings.py, scripts/precompute_pathway_title_embeddings.py, scripts/precompute_go_embeddings.py, scripts/precompute_pathway_embeddings.py</files>
  <action>
    **src/services/embedding.py** — Three loader methods and five cosine computations to update:

    **Loader 1: `_load_precomputed_embeddings()`** — Replace body (currently lines 138–146):
    ```python
    def _load_precomputed_embeddings(self, path: str):
        """Load pre-computed pathway embeddings from NPZ format (no pickle)."""
        npz_path = path.replace('.npy', '.npz')
        if not os.path.exists(npz_path):
            logger.warning("Pathway embeddings file not found: %s", npz_path)
            self.pathway_embeddings = {}
            return
        try:
            with np.load(npz_path) as data:  # allow_pickle=False by default
                ids = data['ids']
                matrix = data['matrix']
            self.pathway_embeddings = dict(zip(ids, matrix))
            logger.info("Loaded %d pre-computed pathway embeddings (normalized)",
                        len(self.pathway_embeddings))
        except Exception as e:
            logger.warning("Could not load pre-computed embeddings: %s", e)
            self.pathway_embeddings = {}
    ```

    **Loader 2: `_load_precomputed_ke_embeddings()`** — Replace body (currently lines 148–156):
    ```python
    def _load_precomputed_ke_embeddings(self, path: str):
        """Load pre-computed KE embeddings from NPZ format (no pickle)."""
        npz_path = path.replace('.npy', '.npz')
        if not os.path.exists(npz_path):
            logger.warning("KE embeddings file not found: %s", npz_path)
            self.ke_embeddings = {}
            return
        try:
            with np.load(npz_path) as data:
                ids = data['ids']
                matrix = data['matrix']
            self.ke_embeddings = dict(zip(ids, matrix))
            logger.info("Loaded %d pre-computed KE embeddings (normalized)",
                        len(self.ke_embeddings))
        except Exception as e:
            logger.warning("Could not load pre-computed KE embeddings: %s", e)
            self.ke_embeddings = {}
    ```

    **Loader 3: `_load_precomputed_pathway_title_embeddings()`** — Replace body (currently lines 158–166). Also update the hardcoded path in `__init__` (line 129–130) from `'data/pathway_title_embeddings.npy'` to `'data/pathway_title_embeddings.npz'`:

    In `__init__`, change:
    ```python
    if os.path.exists('data/pathway_title_embeddings.npy'):
        self._load_precomputed_pathway_title_embeddings('data/pathway_title_embeddings.npy')
    ```
    to:
    ```python
    if os.path.exists('data/pathway_title_embeddings.npz'):
        self._load_precomputed_pathway_title_embeddings('data/pathway_title_embeddings.npz')
    ```

    Method body:
    ```python
    def _load_precomputed_pathway_title_embeddings(self, path: str):
        """Load pre-computed pathway title embeddings from NPZ format (no pickle)."""
        npz_path = path.replace('.npy', '.npz')
        if not os.path.exists(npz_path):
            logger.warning("Pathway title embeddings file not found: %s", npz_path)
            self.pathway_title_embeddings = {}
            return
        try:
            with np.load(npz_path) as data:
                ids = data['ids']
                matrix = data['matrix']
            self.pathway_title_embeddings = dict(zip(ids, matrix))
            logger.info("Loaded %d pre-computed pathway title embeddings (normalized)",
                        len(self.pathway_title_embeddings))
        except Exception as e:
            logger.warning("Could not load pre-computed pathway title embeddings: %s", e)
            self.pathway_title_embeddings = {}
    ```

    **Five cosine → dot product replacements in embedding.py:**

    Replacement 1 — `compute_similarity()` (around line 357):
    ```python
    # OLD:
    raw_similarity = np.dot(emb1, emb2) / (
        np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8
    )
    # NEW (vectors are pre-normalized — dot product IS cosine similarity):
    raw_similarity = np.dot(emb1, emb2)
    ```

    Replacement 2 — `compute_ke_pathway_similarity()` (around line 413):
    ```python
    # OLD:
    raw_desc_sim = np.dot(ke_emb, pathway_emb) / (
        np.linalg.norm(ke_emb) * np.linalg.norm(pathway_emb) + 1e-8
    )
    # NEW:
    raw_desc_sim = np.dot(ke_emb, pathway_emb)
    ```

    Replacement 3 — `compute_batch_similarity()` (around line 463):
    ```python
    # OLD:
    raw_similarities = np.dot(candidate_embs, query_emb) / (
        np.linalg.norm(candidate_embs, axis=1) * np.linalg.norm(query_emb) + 1e-8
    )
    # NEW:
    raw_similarities = np.dot(candidate_embs, query_emb)
    ```

    Replacement 4 — `compute_ke_pathways_batch_similarity()` title computation (around line 541):
    ```python
    # OLD:
    raw_title_similarities = np.dot(pathway_title_embeddings, ke_title_emb) / (
        np.linalg.norm(pathway_title_embeddings, axis=1) * np.linalg.norm(ke_title_emb) + 1e-8
    )
    # NEW:
    raw_title_similarities = np.dot(pathway_title_embeddings, ke_title_emb)
    ```

    Replacement 5 — `compute_ke_pathways_batch_similarity()` description computation (around line 546):
    ```python
    # OLD:
    raw_desc_similarities = np.dot(pathway_full_embeddings, ke_full_emb) / (
        np.linalg.norm(pathway_full_embeddings, axis=1) * np.linalg.norm(ke_full_emb) + 1e-8
    )
    # NEW:
    raw_desc_similarities = np.dot(pathway_full_embeddings, ke_full_emb)
    ```

    Note: `_transform_similarity_score()` and `_transform_similarity_batch()` do NOT change — they still receive raw similarity in [-1, 1] range, and dot product of unit vectors is in the same range. The `(raw_cosine + 1.0) / 2.0` normalization step inside those methods still works correctly.

    **src/suggestions/go.py** — Two loaders to replace:

    **GO Loader 1: `_load_go_embeddings()`** (around line 49–57):
    ```python
    def _load_go_embeddings(self, path):
        """Load pre-computed GO BP embeddings from NPZ format (no pickle)."""
        npz_path = path.replace('.npy', '.npz')
        if os.path.exists(npz_path):
            try:
                with np.load(npz_path) as data:
                    ids = data['ids']
                    matrix = data['matrix']
                self.go_embeddings = dict(zip(ids, matrix))
                logger.info("Loaded %d GO BP embeddings (normalized)", len(self.go_embeddings))
            except Exception as e:
                logger.warning("Could not load GO embeddings: %s", e)
        else:
            logger.warning("GO embeddings file not found: %s", npz_path)
    ```

    **GO Loader 2: `_load_go_name_embeddings()`** (around line 60–68):
    ```python
    def _load_go_name_embeddings(self, path):
        """Load pre-computed GO BP name-only embeddings from NPZ format (no pickle)."""
        npz_path = path.replace('.npy', '.npz')
        if os.path.exists(npz_path):
            try:
                with np.load(npz_path) as data:
                    ids = data['ids']
                    matrix = data['matrix']
                self.go_name_embeddings = dict(zip(ids, matrix))
                logger.info("Loaded %d GO BP name embeddings (normalized)", len(self.go_name_embeddings))
            except Exception as e:
                logger.warning("Could not load GO name embeddings: %s", e)
        else:
            logger.warning("GO name embeddings file not found: %s, will use combined only", npz_path)
    ```

    Also update the GoSuggestionService `__init__` default path arguments (lines 28–29) from `.npy` to `.npz`:
    ```python
    go_embeddings_path='data/go_bp_embeddings.npz',
    go_name_embeddings_path='data/go_bp_name_embeddings.npz',
    ```

    **Precompute scripts** — All 4 scripts call `save_embeddings()` which now writes `.npz`. The scripts themselves just need their output path strings updated from `.npy` to `.npz` if they reference the output path explicitly (e.g., for logging). Check each script for explicit `.npy` path strings and update to `.npz`. The core `save_embeddings()` function call signature is unchanged — callers still pass the old `.npy` path; the function internally strips and rewrites to `.npz`.

    Check each precompute script for hard-coded `.npy` references to output files and update them:
    - `scripts/precompute_ke_embeddings.py`: find any `ke_embeddings.npy` output references → `ke_embeddings.npz`
    - `scripts/precompute_pathway_title_embeddings.py`: find any `pathway_title_embeddings.npy` → `pathway_title_embeddings.npz`
    - `scripts/precompute_go_embeddings.py`: find any `go_bp_embeddings.npy` or `go_bp_name_embeddings.npy` → `.npz`
    - `scripts/precompute_pathway_embeddings.py`: find any `pathway_embeddings.npy` → `pathway_embeddings.npz`

    Since `save_embeddings()` already handles the path transformation internally, the precompute scripts may not need changes beyond any logging/printing that shows file paths. Read each script and update only `.npy` path strings that appear as output references.
  </action>
  <verify>
    Check that no `allow_pickle=True` remains in the embedding loaders:
    ```bash
    grep -n "allow_pickle=True" \
        /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/src/services/embedding.py \
        /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/src/suggestions/go.py
    ```
    Expected: no output (0 matches).

    Check that no cosine norm division remains in embedding.py:
    ```bash
    grep -n "np.linalg.norm.*emb\|linalg.norm.*pathway\|linalg.norm.*ke_" \
        /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/src/services/embedding.py
    ```
    Expected: only the `norms` variable in `save_embeddings` — no norm divisions in similarity computations.

    Run a round-trip test (save + load):
    ```bash
    cd /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping
    python -c "
    import numpy as np, tempfile, os, sys
    sys.path.insert(0, '.')

    # Simulate save
    from scripts.embedding_utils import save_embeddings
    test_embs = {'WP1': np.array([3.0, 4.0]), 'WP2': np.array([1.0, 0.0])}
    with tempfile.TemporaryDirectory() as d:
        save_embeddings(test_embs, os.path.join(d, 'test.npy'))
        with np.load(os.path.join(d, 'test.npz')) as data:
            ids = data['ids']
            matrix = data['matrix']
        loaded = dict(zip(ids, matrix))
        print('Loaded keys:', list(loaded.keys()))
        print('WP1 norm:', np.linalg.norm(loaded['WP1']))  # should be ~1.0
        print('WP2 norm:', np.linalg.norm(loaded['WP2']))  # should be 1.0
        # Dot product of two unit vectors == cosine similarity
        cos = float(np.dot(loaded['WP1'], loaded['WP2']))
        print('dot(WP1, WP2):', cos)
        print('ROUND-TRIP TEST PASSED')
    "
    ```
  </verify>
  <done>No `allow_pickle=True` remains in any embedding loader; all five cosine divisions removed from embedding.py; two GO loaders use NPZ format; GoSuggestionService default paths use .npz; round-trip save/load test passes.</done>
</task>

</tasks>

<verification>
Run the test suite to confirm no regressions from the embedding format change. Tests run with TestingConfig (in-memory DB) and embedding service is disabled in testing — loaders are not called during tests, so tests should pass:

```bash
cd /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping && python -m pytest tests/ -x -q 2>&1 | head -40
```

Also verify no remaining allow_pickle anywhere in the codebase:
```bash
grep -rn "allow_pickle=True" /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/src/ /home/marvin/Documents/Services/Ke-gene-mapping/KE-WP-mapping/scripts/
```
</verification>

<success_criteria>
- `scripts/embedding_utils.py` `save_embeddings()` writes .npz with `ids` (dtype=str Unicode), `matrix` (float32, unit-normalized rows)
- Zero occurrences of `allow_pickle=True` in `src/services/embedding.py` and `src/suggestions/go.py`
- Five cosine similarity computations replaced by `np.dot()` in `embedding.py`
- `GoSuggestionService` default paths use `.npz` extension
- `scoring_config.yaml` embedding paths use `.npz` extension
- Test suite passes (embedding loaders not invoked in tests)
</success_criteria>

<output>
After completion, create `.planning/phases/01-deployment-hardening/01-03-SUMMARY.md` with:
- What was changed and why
- Exact line numbers changed in embedding.py
- Any unexpected findings
- Verification results
</output>
